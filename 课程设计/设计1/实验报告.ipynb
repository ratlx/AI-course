{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cff56bf63abca2b",
   "metadata": {},
   "source": [
    "### 《人工智能》课程设计一\n",
    "#### 实验思路：（该设计是在13周前完成的，当时并未告知只能使用Mindsp框架，相关情况老师已经知晓，请见谅）\n",
    "\n",
    "1.使用tensorflow中的keras作为训练框架\n",
    "\n",
    "2.使用MobileNetV2作为迁移学习的基础模型\n",
    "\n",
    "3.在初次训练基础上，进行微调\n",
    "\n",
    "4.使用随机旋转、水平反转图像，随机重置神经元的方式，缓解过拟合问题\n",
    "### 实验步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T10:03:20.000083Z",
     "start_time": "2024-12-04T10:03:17.598255Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43f2da74fdbb4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 读取数据并进行预处理\n",
    "\n",
    "使用高级 Keras 预处理效用函数tf.keras.utils.image_dataset_from_directory\n",
    "\n",
    "为加载器定义一些参数并加载训练、验证数据集\n",
    "##### （train文件夹，val文件夹，test文件夹，统一放在了data文件夹中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4f233cae05243b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T11:52:14.426154Z",
     "start_time": "2024-11-21T11:52:14.356898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1400 files belonging to 10 classes.\n",
      "Found 200 files belonging to 10 classes.\n",
      "Class Names: ['SUV', 'bus', 'family sedan', 'fire engine', 'heavy truck', 'jeep', 'minibus', 'racing car', 'taxi', 'truck']\n"
     ]
    }
   ],
   "source": [
    "train_directory = 'data/train'  \n",
    "val_directory = 'data/val'\n",
    "batch_size = 32            #批量大小\n",
    "img_size = (160, 160)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_directory,\n",
    "    shuffle=True,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_directory,\n",
    "    shuffle=True,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# 提取类别名\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"Class Names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42efd5dcc718b4",
   "metadata": {},
   "source": [
    "#### 配置数据集以提高性能\n",
    "\n",
    "使用缓冲预提取从磁盘加载图像，以免造成 I/O 阻塞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a377dd00465dcdf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T11:52:29.302362Z",
     "start_time": "2024-11-21T11:52:29.294626Z"
    }
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb04fd3c2a84f6",
   "metadata": {},
   "source": [
    "#### 使用数据扩充\n",
    "\n",
    "由于提供的数据集规模不大，引入随机旋转和水平翻转，增加数据的多样性。有助于缓解过拟合的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "548e74cb75966940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T11:54:55.555177Z",
     "start_time": "2024-11-21T11:54:55.543981Z"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.0005),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645bed2cc000d62",
   "metadata": {},
   "source": [
    "#### 重新缩放像素值\n",
    "\n",
    "使用tf.keras.applications.MobileNetV2 作为基础模型。此模型期望像素值处于 [-1, 1] 范围内，但此时，图像中的像素值处于 [0, 255] 范围内。要重新缩放这些像素值，此时使用模型随附的预处理方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf287a7ebfa6872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T11:57:28.635028Z",
     "start_time": "2024-11-21T11:57:28.632964Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d023eaab81eab8f",
   "metadata": {},
   "source": [
    "#### 从预训练卷积网络创建基础模型\n",
    "\n",
    "根据 Google 开发的 MobileNet V2 模型来创建基础模型。此模型已基于 ImageNet 数据集进行预训练，ImageNet 数据集是一个包含 140 万个图像和 1000 个类的大型数据集。ImageNet 是一个研究训练数据集，具有各种各样的类别。\n",
    "\n",
    "将 MobileNet V2 用于展平操作之前的最后一层，用于特征提取。此层被称为“瓶颈层”。与最后一层/顶层相比，瓶颈层的特征保留了更多的通用性。\n",
    "\n",
    "首先，实例化一个已预加载基于 ImageNet 训练的权重的 MobileNet V2 模型。通过指定 include_top=False 参数，可以加载不包括顶部分类层的网络，这对于特征提取十分理想。\n",
    "\n",
    "其次，在编译和训练模型之前，冻结卷积基至关重要。冻结（通过设置 layer.trainable = False）可避免在训练期间更新给定层中的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8fa5043f57fe794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:06:01.539761Z",
     "start_time": "2024-11-21T12:06:00.710412Z"
    }
   },
   "outputs": [],
   "source": [
    "img_shape = img_size + (3,)  # 添加通道数\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=img_shape,\n",
    "    include_top=False,  # 不加载顶层分类器\n",
    "    weights='imagenet'  \n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c346a251f76de51",
   "metadata": {},
   "source": [
    "#### 添加分类头\n",
    "\n",
    "要从特征块生成预测，使用 tf.keras.layers.GlobalAveragePooling2D 层在 5x5 空间位置内取平均值，以将特征转换成每个图像一个向量（包含 1280 个元素）。\n",
    "\n",
    "预测的输出数为10，使用softmax，将输入的未归一化的数值转换为概率分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7064e3876e413ab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:18:23.330532Z",
     "start_time": "2024-11-21T12:18:23.324408Z"
    }
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30430540a99c130",
   "metadata": {},
   "source": [
    "通过使用 Keras 函数式 API 将数据扩充、重新缩放、base_model 和特征提取程序层链接在一起来构建模型。如前面所述，由于模型包含 BatchNormalization 层，因此使用 training = False。训练模型过程中，使用data_augmentation对数据进行增强；preprocess_input对数据进行预处理，及转换成mobilenetV2的输入格式；base_model将输入数据传入预训练的基础模型（mobilenetV2），并进行特征提取；global_average_layer对基础模型的输出进行全局平均池化，通过这种方式，模型可以得到一个更加紧凑的特征表示，用作于替代全连接层；Dropout 是一种正则化技术，通过在训练时随机忽略部分神经元（通过置零），避免模型过拟合，它有效地减少了神经网络对某些神经元的依赖，使得模型更具泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3da2facacc3fb7a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:22:48.742357Z",
     "start_time": "2024-11-21T12:22:48.567824Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=img_shape)\n",
    "x = data_augmentation(inputs)      #数据扩充\n",
    "x = preprocess_input(x)  # [0,255]--->[-1,1]\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # 随机重置20%神经元，防止过拟合\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43ef31adfc1eb86",
   "metadata": {},
   "source": [
    "#### 编译模型\n",
    "\n",
    "使用Adam优化器，SparseCategoricalCrossentropy作为分类问题的交叉熵损失函数，指定评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b7fc9ce94392b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:25:53.845405Z",
     "start_time": "2024-11-21T12:25:53.830280Z"
    }
   },
   "outputs": [],
   "source": [
    "base_learning_rate=0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53d598f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:30:51.523327Z",
     "start_time": "2024-11-21T12:30:51.502435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 160, 160, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 160, 160, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenetv2_1.00_160 (Funct  (None, 5, 5, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276ff5b7557f083",
   "metadata": {},
   "source": [
    "MobileNetV2 是一种预训练的深度学习模型，它的最后一个可用的卷积层输出大小是 (None, 5, 5, 1280)，即每张输入图片经过卷积运算后，变成了一个 5x5 的特征图，并且有 1280 个通道。这是 MobileNetV2 的默认设计，无论调整输入大小如何，它都会将高层特征压缩到 1280 个通道。\n",
    "\n",
    "在模型中，Dense 层的作用是将从 GlobalAveragePooling2D 层得到的 (None, 1280) 输入映射到 (None, 10)，即最终的分类输出。Dense 层的参数计算如下：\n",
    "##### (1280+1)*10=12810\n",
    "加 1 是因为每个输出神经元还有一个偏置（bias）参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afecb406803613d",
   "metadata": {},
   "source": [
    "\n",
    "#### 训练模型\n",
    "\n",
    "经过实验，15为较好的循环值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9875745ad8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 15\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=initial_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f096f04d1b9ce85",
   "metadata": {},
   "source": [
    "#### 学习曲线\n",
    "\n",
    "我们看一下使用 MobileNet V2 基础模型作为固定特征提取程序时训练和验证准确率/损失的学习曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e230423750fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_directory='result'\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,3.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(os.path.join(result_directory, f\"学习曲线.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301d27bf6e1e0a3",
   "metadata": {},
   "source": [
    "![学习曲线](result/学习曲线.png)\n",
    "\n",
    "验证指标明显优于训练指标，主要原因是 tf.keras.layers.BatchNormalization 和 tf.keras.layers.Dropout 等层会影响训练期间的准确率。在计算验证损失时，它们处于关闭状态。\n",
    "\n",
    "#### 微调\n",
    "\n",
    "由上图可知，此时训练已经到达瓶颈，此时可以采用微调操作。\n",
    "\n",
    "在特征提取实验中，仅在 MobileNet V2 基础模型的顶部训练了一些层。预训练网络的权重在训练过程中未更新。\n",
    "\n",
    "进一步提高性能的一种方式是在训练（或“微调”）预训练模型顶层的权重的同时，同时训练添加的分类器。训练过程将强制权重从通用特征映射调整为专门与数据集相关联的特征。\n",
    "\n",
    "另外，还应尝试微调少量顶层而不是整个 MobileNet 模型。在大多数卷积网络中，层越高，它的专门程度就越高。前几层学习非常简单且通用的特征，这些特征可以泛化到几乎所有类型的图像。随着您向上层移动，这些特征越来越特定于训练模型所使用的数据集。微调的目标是使这些专用特征适应新的数据集，而不是覆盖通用学习。\n",
    "\n",
    "#### 解冻模型的顶层\n",
    "\n",
    "解冻90层以上的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b84928c6feb3fee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:45:15.398423Z",
     "start_time": "2024-11-21T13:45:15.380221Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_at = 90  # 微调的层数\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1369a6f835fa819",
   "metadata": {},
   "source": [
    "#### 编译模型\n",
    "\n",
    "此阶段应使用较低的学习率。否则，模型可能会很快过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82542b1ca3403808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:47:46.122129Z",
     "start_time": "2024-11-21T12:47:46.098126Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d433fb6ab5bfa779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:45:24.184578Z",
     "start_time": "2024-11-21T13:45:24.165487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 160, 160, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 160, 160, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenetv2_1.00_160 (Funct  (None, 5, 5, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 1,997,322\n",
      "Non-trainable params: 273,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c42122f2129982",
   "metadata": {},
   "source": [
    "#### 继续训练模型\n",
    "\n",
    "共训练10个循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f33bae660666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca58a5b13b3a9d3",
   "metadata": {},
   "source": [
    "#### 微调曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff40ab9d396644",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a168bc8e569867",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.5])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig(os.path.join(result_directory, f\"微调学习曲线.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3b05ab86ea560",
   "metadata": {},
   "source": [
    "![微调曲线](result/微调曲线.png)\n",
    "\n",
    "可以看到验证准确率由88%提高到92%，训练准确率也从90%提高到97%。但是训练了21个循环后，出现了验证损失大于训练损失的情况，说明可能出现过拟合的情况。因此训练设定为25个循环，防止过度拟合的加剧。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb667c45b74181c",
   "metadata": {},
   "source": [
    "#### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de676b210b9667ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('car_classification.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa398781338b8",
   "metadata": {},
   "source": [
    "\n",
    "#### 评估和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4dce0cb64676e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "model = tf.keras.models.load_model('car_classification.keras')   #加载模型\n",
    "\n",
    "test_images=[]\n",
    "test_directory = 'data/test'\n",
    "img_size = (160, 160)\n",
    "batch_size = 32\n",
    "result_directory = 'result'\n",
    "\n",
    "class_names = ['SUV', 'bus', 'family sedan', 'fire engine', 'heavy truck', 'jeep', 'minibus', 'racing car', 'taxi', 'truck']\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_directory,\n",
    "    labels=None,\n",
    "    shuffle=False,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "predictons = model.predict(test_dataset)\n",
    "\n",
    "images = []\n",
    "for batch in test_dataset:\n",
    "    for img in batch:\n",
    "        images.append(img.numpy())\n",
    "\n",
    "for i in range(0, len(predictons), 25):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for j in range(25):\n",
    "        plt.subplot(5, 5, j + 1)\n",
    "        plt.imshow(images[i + j].astype(\"uint8\"))\n",
    "        plt.title(f\"Predicted: {class_names[np.argmax(predictons[i + j])]}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(os.path.join(result_directory, f\"result_{int(i/25+1)}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f93e44086d4f3e",
   "metadata": {},
   "source": [
    "#### 数据分析\n",
    "\n",
    "##### 根据下图，可统计出200张照片中，共有12张图片识别错误，准确率为94%，与训练时计算的准确度吻合。\n",
    "##### （对图像进行了图画，格式由.png自动转换成.jpeg)\n",
    "\n",
    "![数据集一](result/result_1.jpeg)\n",
    "![数据集二](result/result_2.jpeg)\n",
    "![数据集三](result/result_3.jpeg)\n",
    "![数据集四](result/result_4.jpeg)\n",
    "![数据集五](result/result_5.jpeg)\n",
    "![数据集六](result/result_6.jpeg)\n",
    "![数据集七](result/result_7.jpeg)\n",
    "![数据集八](result/result_8.jpeg)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
